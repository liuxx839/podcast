import streamlit as st
import requests
import json
import os
import tempfile
from pydub import AudioSegment
from openai import OpenAI
import docx
import PyPDF2

# --- Configuration & Constants ---
OPENAI_API_KEY = os.getenv("GEMINI_API_KEY")
MINIMAX_GROUP_ID = os.getenv("MINIMAX_GROUP_ID")
MINIMAX_API_KEY = os.getenv("MINIMAX_API_KEY")

VOICE_OPTIONS = {
    "é’æ¶©é’å¹´éŸ³è‰²": "male-qn-qingse", "ç²¾è‹±é’å¹´éŸ³è‰²": "male-qn-jingying", "éœ¸é“é’å¹´éŸ³è‰²": "male-qn-badao",
    "é’å¹´å¤§å­¦ç”ŸéŸ³è‰²": "male-qn-daxuesheng", "å°‘å¥³éŸ³è‰²": "female-shaonv", "å¾¡å§éŸ³è‰²": "female-yujie",
    "æˆç†Ÿå¥³æ€§éŸ³è‰²": "female-chengshu", "ç”œç¾å¥³æ€§éŸ³è‰²": "female-tianmei", "ç”·æ€§ä¸»æŒäºº": "presenter_male",
    "å¥³æ€§ä¸»æŒäºº": "presenter_female", "ç”·æ€§æœ‰å£°ä¹¦1": "audiobook_male_1", "ç”·æ€§æœ‰å£°ä¹¦2": "audiobook_male_2",
    "å¥³æ€§æœ‰å£°ä¹¦1": "audiobook_female_1", "å¥³æ€§æœ‰å£°ä¹¦2": "audiobook_female_2",
    "é’æ¶©é’å¹´éŸ³è‰²-beta": "male-qn-qingse-jingpin", "ç²¾è‹±é’å¹´éŸ³è‰²-beta": "male-qn-jingying-jingpin",
    "éœ¸é“é’å¹´éŸ³è‰²-beta": "male-qn-badao-jingpin", "é’å¹´å¤§å­¦ç”ŸéŸ³è‰²-beta": "male-qn-daxuesheng-jingpin",
    "å°‘å¥³éŸ³è‰²-beta": "female-shaonv-jingpin", "å¾¡å§éŸ³è‰²-beta": "female-yujie-jingpin",
    "æˆç†Ÿå¥³æ€§éŸ³è‰²-beta": "female-chengshu-jingpin", "ç”œç¾å¥³æ€§éŸ³è‰²-beta": "female-tianmei-jingpin",
    "èªæ˜ç”·ç«¥": "clever_boy", "å¯çˆ±ç”·ç«¥": "cute_boy", "èŒèŒå¥³ç«¥": "lovely_girl", "å¡é€šçŒªå°çª": "cartoon_pig",
    "ç—…å¨‡å¼Ÿå¼Ÿ": "bingjiao_didi", "ä¿Šæœ—ç”·å‹": "junlang_nanyou", "çº¯çœŸå­¦å¼Ÿ": "chunzhen_xuedi",
    "å†·æ·¡å­¦é•¿": "lengdan_xiongzhang", "éœ¸é“å°‘çˆ·": "badao_shaoye", "ç”œå¿ƒå°ç²": "tianxin_xiaoling",
    "ä¿çš®èŒå¦¹": "qiaopi_mengmei", "å¦©åªšå¾¡å§": "wumei_yujie", "å—²å—²å­¦å¦¹": "diadia_xuemei",
    "æ·¡é›…å­¦å§": "danya_xuejie"
}

DIALOGUE_STYLES = {
    "è½»æ¾å¹½é»˜": "ä»¥è½»æ¾ã€å¹½é»˜çš„æ–¹å¼è¿›è¡Œå¯¹è¯ï¼ŒåŠ å…¥é€‚å½“çš„ç¬‘è¯å’Œè½»æ¾çš„è¯­æ°”ã€‚",
    "ä¸“ä¸šæ·±å…¥": "ä»¥ä¸“ä¸šã€æ·±å…¥çš„æ–¹å¼æ¢è®¨ä¸»é¢˜ï¼Œæ³¨é‡ç»†èŠ‚å’Œé€»è¾‘åˆ†æã€‚",
    "ç”ŸåŠ¨å™äº‹": "ä»¥æ•…äº‹åŒ–ã€å½¢è±¡åŒ–çš„æ–¹å¼å™è¿°ï¼Œå¢å¼ºå¬ä¼—çš„æ²‰æµ¸æ„Ÿã€‚",
    "æ¿€çƒˆäº‰è¾©": "ä»¥å¯¹ç«‹ã€äº‰è¾©çš„é£æ ¼å±•å¼€å¯¹è¯ï¼Œçªå‡ºä¸åŒè§‚ç‚¹çš„ç¢°æ’ã€‚"
}

MINIMAX_API_URL_TEMPLATE = "https://api.minimax.chat/v1/t2a_v2?GroupId={group_id}"

# --- Initialize Session State ---
if 'extracted_content' not in st.session_state:
    st.session_state.extracted_content = None
if 'dialogue_script' not in st.session_state:
    st.session_state.dialogue_script = None
if 'final_audio_path' not in st.session_state:
    st.session_state.final_audio_path = None
if 'json_script_data' not in st.session_state:
    st.session_state.json_script_data = None
if 'edited_dialogue' not in st.session_state:
    st.session_state.edited_dialogue = None
if 'character_recommendations' not in st.session_state:
    st.session_state.character_recommendations = None

# --- Helper Functions ---
def extract_text_from_file(uploaded_file):
    """Extract text from uploaded file (.txt, .pdf, .docx)."""
    if uploaded_file.name.endswith(".txt"):
        return uploaded_file.read().decode("utf-8")
    elif uploaded_file.name.endswith(".pdf"):
        try:
            text = ""
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶æ¥ä¿å­˜ä¸Šä¼ çš„PDF
            with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as temp_file:
                temp_file.write(uploaded_file.getbuffer())
                temp_file_path = temp_file.name
            
            # ä½¿ç”¨PyPDF2è¯»å–ä¸´æ—¶æ–‡ä»¶
            pdf_reader = PyPDF2.PdfReader(temp_file_path)
            for page_num in range(len(pdf_reader.pages)):
                page = pdf_reader.pages[page_num]
                try:
                    page_text = page.extract_text()
                    if page_text:  # ç¡®ä¿æå–çš„æ–‡æœ¬ä¸ä¸ºç©º
                        text += page_text + "\n"
                except Exception as e:
                    st.warning(f"æ— æ³•æå–PDFç¬¬{page_num+1}é¡µæ–‡æœ¬: {e}")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(temp_file_path)
            
            # å¦‚æœæ²¡æœ‰æå–åˆ°ä»»ä½•æ–‡æœ¬ï¼Œè¿”å›é”™è¯¯
            if not text.strip():
                st.error("æ— æ³•ä»PDFä¸­æå–æœ‰æ•ˆæ–‡æœ¬ã€‚æ–‡ä»¶å¯èƒ½æ˜¯æ‰«æä»¶æˆ–å—ä¿æŠ¤ã€‚")
                return None
                
            # æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤å¯èƒ½å¯¼è‡´é—®é¢˜çš„å­—ç¬¦
            text = ''.join(char for char in text if ord(char) < 65536)
            return text
            
        except Exception as e:
            st.error(f"å¤„ç†PDFæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return None
    elif uploaded_file.name.endswith(".docx"):
        doc = docx.Document(uploaded_file)
        text = "\n".join([paragraph.text for paragraph in doc.paragraphs])
        return text
    else:
        st.error("ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ã€‚è¯·ä¸Šä¼  .txt, .pdf æˆ– .docx æ–‡ä»¶")
        return None

def generate_dialogue_openai(content, char1_name, char2_name, dialogue_style, model="gemini-2.0-flash"):
    """Generate dialogue using OpenAI API."""
    client = OpenAI(api_key=OPENAI_API_KEY, base_url="https://generativelanguage.googleapis.com/v1beta/")
    style_instruction = DIALOGUE_STYLES[dialogue_style]
    prompt = f"""
    æ ¹æ®ä»¥ä¸‹å†…å®¹ï¼Œä¸ºä¸¤ä¸ªè§’è‰²ï¼ˆ{char1_name} å’Œ {char2_name}ï¼‰ç”Ÿæˆä¸€æ®µå¼•äººå…¥èƒœçš„æ’­å®¢å¯¹è¯ã€‚
    å¯¹è¯åº”ä»¥{style_instruction}çš„æ–¹å¼ï¼Œæ·±å…¥æ¢è®¨å†…å®¹çš„ä¸»é¢˜å’Œä¿¡æ¯ï¼Œä»¥å¯¹è¯å½¢å¼å‘ˆç°ã€‚æœ€å¤š3è½®å¯¹è¯ã€‚
    è¾“å‡ºæ ¼å¼ä¸º JSON åˆ—è¡¨ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å« "speaker" é”®ï¼ˆå€¼ä¸º "{char1_name}" æˆ– "{char2_name}"ï¼‰å’Œ "line" é”®ï¼ˆè§’è‰²æ‰€è¯´çš„è¯ï¼‰ã€‚
    ä¸è¦åœ¨ JSON åˆ—è¡¨ä¹‹å¤–åŒ…å«ä»»ä½•å…¶ä»–æ–‡æœ¬æˆ–è¯´æ˜ã€‚

    å†…å®¹ï¼š
    ---
    {content}
    ---

    JSON è¾“å‡ºï¼š
    """
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå¯Œæœ‰åˆ›æ„çš„æ’­å®¢è„šæœ¬ä½œè€…ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
        )
        dialogue_json_str = response.choices[0].message.content.strip()
        
        if dialogue_json_str.startswith("```json"):
            dialogue_json_str = dialogue_json_str[7:]
        if dialogue_json_str.endswith("```"):
            dialogue_json_str = dialogue_json_str[:-3]
        dialogue_json_str = dialogue_json_str.strip()

        dialogue = json.loads(dialogue_json_str)
        if not isinstance(dialogue, list) or not all(
            isinstance(item, dict) and "speaker" in item and "line" in item for item in dialogue
        ):
            st.error(f"AI è¿”å›çš„å¯¹è¯æ ¼å¼ä¸æ­£ç¡®ã€‚åŸå§‹è¾“å‡ºï¼š{dialogue_json_str}")
            return None
        return dialogue
    except json.JSONDecodeError:
        st.error(f"æ— æ³•è§£æ AI å“åº”ä¸º JSONã€‚åŸå§‹è¾“å‡ºï¼š{dialogue_json_str}")
        return None
    except Exception as e:
        st.error(f"ä½¿ç”¨ OpenAI ç”Ÿæˆå¯¹è¯æ—¶å‡ºé”™ï¼š{e}")
        return None

def recommend_characters_and_voices(content):
    """Analyze content and recommend character names, voices, and dialogue style using OpenAI."""
    client = OpenAI(api_key=OPENAI_API_KEY, base_url="https://generativelanguage.googleapis.com/v1beta/")
    prompt = f"""
    æ ¹æ®ä»¥ä¸‹å†…å®¹ï¼Œæ¨èä¸¤ä¸ªé€‚åˆè¿›è¡Œæ’­å®¢å¯¹è¯çš„è§’è‰²åå­—ï¼ˆä¾‹å¦‚ï¼Œåå­—åº”åæ˜ å†…å®¹ä¸»é¢˜æˆ–è§’è‰²èƒŒæ™¯ï¼‰ï¼Œ
    æ¯ä¸ªè§’è‰²çš„éŸ³è‰²ï¼ˆä»ä»¥ä¸‹éŸ³è‰²åˆ—è¡¨ä¸­é€‰æ‹©ï¼š{', '.join(VOICE_OPTIONS.keys())}ï¼‰ï¼Œ
    ä»¥åŠä¸€ä¸ªé€‚åˆå†…å®¹çš„å¯¹è¯é£æ ¼ï¼ˆä»ä»¥ä¸‹é£æ ¼ä¸­é€‰æ‹©ï¼š{', '.join(DIALOGUE_STYLES.keys())}ï¼‰ã€‚
    è¾“å‡º JSON æ ¼å¼ï¼ŒåŒ…å«ä¸¤ä¸ªè§’è‰²ï¼Œæ¯ä¸ªè§’è‰²æœ‰ "name" å’Œ "voice" é”®ï¼Œä»¥åŠä¸€ä¸ª "dialogue_style" é”®è¡¨ç¤ºæ¨èçš„å¯¹è¯é£æ ¼ã€‚
    
    å†…å®¹ï¼š
    ---
    {content}
    ---

    JSON è¾“å‡ºï¼š
    {{
        "characters": [
            {{"name": "è§’è‰²1åå­—", "voice": "éŸ³è‰²åç§°"}},
            {{"name": "è§’è‰²2åå­—", "voice": "éŸ³è‰²åç§°"}}
        ],
        "dialogue_style": "å¯¹è¯é£æ ¼åç§°"
    }}
    """
    try:
        response = client.chat.completions.create(
            model="gemini-2.0-flash",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ“…é•¿åˆ†ææ–‡æœ¬å¹¶æ¨èæ’­å®¢è§’è‰²å’Œå¯¹è¯é£æ ¼çš„ AIã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
        )
        response_json_str = response.choices[0].message.content.strip()
        
        if response_json_str.startswith("```json"):
            response_json_str = response_json_str[7:]
        if response_json_str.endswith("```"):
            response_json_str = response_json_str[:-3]
        response_json_str = response_json_str.strip()

        recommendations = json.loads(response_json_str)
        if (
            not isinstance(recommendations, dict) or
            "characters" not in recommendations or
            "dialogue_style" not in recommendations or
            not isinstance(recommendations["characters"], list) or
            len(recommendations["characters"]) != 2 or
            not all(
                isinstance(item, dict) and "name" in item and "voice" in item and item["voice"] in VOICE_OPTIONS
                for item in recommendations["characters"]
            ) or
            recommendations["dialogue_style"] not in DIALOGUE_STYLES
        ):
            st.warning(f"AI æ¨èçš„æ ¼å¼ä¸æ­£ç¡®ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼ã€‚åŸå§‹è¾“å‡ºï¼š{response_json_str}")
            return {
                "characters": [
                    {"name": "Alice", "voice": "å°‘å¥³éŸ³è‰²"},
                    {"name": "Bob", "voice": "é’æ¶©é’å¹´éŸ³è‰²"}
                ],
                "dialogue_style": "è½»æ¾å¹½é»˜"
            }
        return recommendations
    except Exception as e:
        st.warning(f"æ¨èè§’è‰²å’Œå¯¹è¯é£æ ¼æ—¶å‡ºé”™ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼ï¼š{e}")
        return {
            "characters": [
                {"name": "Alice", "voice": "å°‘å¥³éŸ³è‰²"},
                {"name": "Bob", "voice": "é’æ¶©é’å¹´éŸ³è‰²"}
            ],
            "dialogue_style": "è½»æ¾å¹½é»˜"
        }

def text_to_speech_minimax(text_to_speak, voice_id):
    """Generate speech using Minimax API and return audio content."""
    url = MINIMAX_API_URL_TEMPLATE.format(group_id=MINIMAX_GROUP_ID)
    headers = {
        "Authorization": f"Bearer {MINIMAX_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "speech-02-turbo",
        "text": text_to_speak,
        "timber_weights": [
            {
                "voice_id": voice_id,
                "weight": 100
            }
        ],
        "voice_setting": {
            "voice_id": "",
            "speed": 1.0,
            "pitch": 0,
            "vol": 1.0,
            "latex_read": False
        },
        "audio_setting": {
            "sample_rate": 32000,
            "bitrate": 128000,
            "format": "mp3"
        },
        "language_boost": "auto"
    }

    try:
        response = requests.post(url, headers=headers, json=payload, timeout=60)
        response.raise_for_status()
        
        parsed_json = response.json()
        
        if 'data' not in parsed_json or 'audio' not in parsed_json['data']:
            st.error(f"Minimax API æœªè¿”å›éŸ³é¢‘æ•°æ®ã€‚å“åº”ï¼š{response.text}")
            return None
        
        audio_hex = parsed_json['data']['audio']
        try:
            audio_content = bytes.fromhex(audio_hex)
            return audio_content
        except ValueError as ve:
            st.error(f"æ— æ³•å°†éŸ³é¢‘æ•°æ®ä»åå…­è¿›åˆ¶è§£ç ï¼š{ve}")
            return None
            
    except requests.exceptions.RequestException as e:
        st.error(f"è°ƒç”¨ Minimax API æ—¶å‡ºé”™ï¼š{e}")
        return None
    except json.JSONDecodeError as je:
        st.error(f"æ— æ³•è§£æ Minimax API å“åº”ä¸º JSONï¼š{response.text}")
        return None

def concatenate_audio_files(audio_files_paths, output_path):
    """Concatenate multiple MP3 files into one."""
    if not audio_files_paths:
        return None
    
    combined = AudioSegment.empty()
    try:
        for file_path in audio_files_paths:
            segment = AudioSegment.from_mp3(file_path)
            combined += segment
        combined.export(output_path, format="mp3")
        return output_path
    except Exception as e:
        st.error(f"éŸ³é¢‘åˆå¹¶æ—¶å‡ºé”™ï¼š{e}")
        st.error("è¯·ç¡®ä¿å·²å®‰è£… ffmpeg å¹¶å°†å…¶æ·»åŠ åˆ°ç³»ç»Ÿ PATH ä¸­ã€‚")
        return None

# --- Streamlit App UI ---
st.set_page_config(layout="wide", page_title="AI æ’­å®¢ç”Ÿæˆå™¨")
st.title("ğŸ™ï¸ AI æ’­å®¢ç”Ÿæˆå™¨")

# --- Sidebar for Inputs ---
with st.sidebar:
    st.header("âš™ï¸ é…ç½®")
    
    st.subheader("ğŸ“œ å†…å®¹è¾“å…¥")
    uploaded_file = st.file_uploader("ä¸Šä¼ å†…å®¹ï¼ˆtxt, pdf, docxï¼‰", type=["txt", "pdf", "docx"])
    raw_text_input = st.text_area("æˆ–åœ¨æ­¤ç²˜è´´æ–‡æœ¬å†…å®¹", height=150)

    st.divider()

    st.subheader("ğŸ—£ï¸ æ’­å®¢è§’è‰²(ç‚¹å‡»ä¸‹æ–¹ç”Ÿæˆå¯¹è¯è„šæœ¬ä¼šè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„persona)")

    if st.session_state.extracted_content and not st.session_state.character_recommendations:
        with st.spinner("æ­£åœ¨åˆ†æå†…å®¹å¹¶æ¨èè§’è‰²å’Œå¯¹è¯é£æ ¼..."):
            st.session_state.character_recommendations = recommend_characters_and_voices(st.session_state.extracted_content)
    elif not st.session_state.extracted_content:
        st.info("è¯·å…ˆä¸Šä¼ æ–‡ä»¶æˆ–è¾“å…¥æ–‡æœ¬å†…å®¹ä»¥ç”Ÿæˆè§’è‰²å’Œå¯¹è¯é£æ ¼æ¨èã€‚")

    default_char1 = (
        st.session_state.character_recommendations["characters"][0]
        if st.session_state.character_recommendations
        else {"name": "Alice", "voice": "å°‘å¥³éŸ³è‰²"}
    )
    default_char2 = (
        st.session_state.character_recommendations["characters"][1]
        if st.session_state.character_recommendations
        else {"name": "Bob", "voice": "é’æ¶©é’å¹´éŸ³è‰²"}
    )
    default_dialogue_style = (
        st.session_state.character_recommendations["dialogue_style"]
        if st.session_state.character_recommendations
        else "è½»æ¾å¹½é»˜"
    )

    st.write(f"**è§’è‰² 1ï¼ˆæ¨èï¼š{default_char1['name']}, éŸ³è‰²ï¼š{default_char1['voice']}ï¼‰**")
    char1_name = st.text_input("è§’è‰² 1 å§“å", value=default_char1['name'], key="char1_name")
    char1_voice_name = st.selectbox(
        f"{char1_name} çš„éŸ³è‰²",
        options=list(VOICE_OPTIONS.keys()),
        index=list(VOICE_OPTIONS.keys()).index(default_char1['voice']),
        key="char1_voice"
    )
    char1_voice_id = VOICE_OPTIONS[char1_voice_name]

    st.write(f"**è§’è‰² 2ï¼ˆæ¨èï¼š{default_char2['name']}, éŸ³è‰²ï¼š{default_char2['voice']}ï¼‰**")
    char2_name = st.text_input("è§’è‰² 2 å§“å", value=default_char2['name'], key="char2_name")
    char2_voice_name = st.selectbox(
        f"{char2_name} çš„éŸ³è‰²",
        options=list(VOICE_OPTIONS.keys()),
        index=list(VOICE_OPTIONS.keys()).index(default_char2['voice']),
        key="char2_voice"
    )
    char2_voice_id = VOICE_OPTIONS[char2_voice_name]

    st.subheader("ğŸ’¬ å¯¹è¯é£æ ¼")
    st.write(f"**æ¨èå¯¹è¯é£æ ¼ï¼š{default_dialogue_style}**")
    dialogue_style = st.selectbox(
        "é€‰æ‹©å¯¹è¯é£æ ¼",
        options=list(DIALOGUE_STYLES.keys()),
        index=list(DIALOGUE_STYLES.keys()).index(default_dialogue_style),
        key="dialogue_style"
    )
    
    st.divider()
    generate_dialogue_button = st.button("ğŸ“ ç”Ÿæˆå¯¹è¯è„šæœ¬", type="primary", use_container_width=True)

# --- Main Area for Output ---
# 1. Display extracted content if file uploaded
if uploaded_file:
    with st.spinner("æ­£åœ¨ä»æ–‡ä»¶ä¸­æå–æ–‡æœ¬..."):
        content = extract_text_from_file(uploaded_file)
        if content:
            st.session_state.extracted_content = content
            st.subheader("ğŸ“„ æå–çš„å†…å®¹")
            st.text_area("æå–çš„æ–‡æœ¬", content, height=200, disabled=True)
        else:
            st.error("æ— æ³•ä»ä¸Šä¼ çš„æ–‡ä»¶ä¸­æå–å†…å®¹ã€‚")
            st.stop()
elif raw_text_input:
    st.session_state.extracted_content = raw_text_input

# 2. Generate dialogue
if generate_dialogue_button:
    st.session_state.dialogue_script = None
    st.session_state.final_audio_path = None
    st.session_state.json_script_data = None
    st.session_state.edited_dialogue = None

    content = st.session_state.extracted_content
    if not content:
        st.warning("è¯·ä¸Šä¼ æ–‡ä»¶æˆ–ç²˜è´´æ–‡æœ¬å†…å®¹ã€‚")
        st.stop()

    with st.spinner(f"AI æ­£åœ¨ä¸º {char1_name} å’Œ {char2_name} ç¼–å†™å¯¹è¯...ï¼ˆè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼‰"):
        dialogue = generate_dialogue_openai(content, char1_name, char2_name, dialogue_style)
    
    if not dialogue:
        st.error("ç”Ÿæˆå¯¹è¯å¤±è´¥ã€‚")
        st.stop()

    st.session_state.dialogue_script = dialogue
    st.session_state.edited_dialogue = json.dumps(dialogue, indent=2, ensure_ascii=False)
    st.session_state.json_script_data = st.session_state.edited_dialogue.encode('utf-8')

# 3. Display and edit dialogue
if st.session_state.dialogue_script:
    st.subheader("ğŸ’¬ ç”Ÿæˆçš„å¯¹è¯è„šæœ¬ï¼ˆå¯ç¼–è¾‘ï¼‰")
    edited_text = st.text_area(
        "ç¼–è¾‘å¯¹è¯è„šæœ¬ï¼ˆJSON æ ¼å¼ï¼‰",
        st.session_state.edited_dialogue,
        height=400
    )
    
    try:
        edited_dialogue = json.loads(edited_text)
        if not isinstance(edited_dialogue, list) or not all(
            isinstance(item, dict) and "speaker" in item and "line" in item for item in edited_dialogue
        ):
            st.error("ç¼–è¾‘åçš„å¯¹è¯æ ¼å¼ä¸æ­£ç¡®ã€‚è¯·ç¡®ä¿ä¸ºæœ‰æ•ˆçš„ JSON åˆ—è¡¨ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å« 'speaker' å’Œ 'line' é”®ã€‚")
        else:
            st.session_state.edited_dialogue = edited_text
            st.session_state.json_script_data = edited_text.encode('utf-8')
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½å¯¹è¯è„šæœ¬ (JSON)",
                data=st.session_state.json_script_data,
                file_name="podcast_script.json",
                mime="application/json"
            )
            
            if st.button("ğŸš€ ç”Ÿæˆæ’­å®¢", type="primary"):
                st.session_state.final_audio_path = None
                
                dialogue = edited_dialogue
                individual_audio_files = []
                temp_dir = tempfile.mkdtemp()

                generation_errors = False
                with st.spinner("æ­£åœ¨å°†å¯¹è¯è½¬æ¢ä¸ºè¯­éŸ³å¹¶ç»„è£…æ’­å®¢..."):
                    progress_bar = st.progress(0)
                    total_lines = len(dialogue)

                    for i, turn in enumerate(dialogue):
                        speaker_name = turn.get("speaker")
                        line_text = turn.get("line")

                        if not speaker_name or not line_text:
                            st.warning(f"è·³è¿‡æ— æ•ˆå¯¹è¯ç‰‡æ®µï¼š{turn}")
                            continue

                        voice_id_to_use = char1_voice_id if speaker_name == char1_name else char2_voice_id
                        
                        status_placeholder = st.empty()
                        status_placeholder.info(f"æ­£åœ¨ä¸º {speaker_name} ç”ŸæˆéŸ³é¢‘ï¼š\"{line_text[:30]}...\"")
                        
                        audio_content = text_to_speech_minimax(line_text, voice_id_to_use)
                        
                        if audio_content:
                            temp_audio_path = os.path.join(temp_dir, f"line_{i+1}.mp3")
                            with open(temp_audio_path, "wb") as f:
                                f.write(audio_content)
                            individual_audio_files.append(temp_audio_path)
                        else:
                            st.error(f"æ— æ³•ä¸ºä»¥ä¸‹å†…å®¹ç”ŸæˆéŸ³é¢‘ï¼š{speaker_name} - \"{line_text}\"")
                            generation_errors = True
                        
                        progress_bar.progress((i + 1) / total_lines)
                        status_placeholder.empty()

                    if generation_errors and not individual_audio_files:
                        st.error("æœªç”Ÿæˆä»»ä½•éŸ³é¢‘æ–‡ä»¶ï¼Œæ— æ³•åˆ›å»ºæ’­å®¢ã€‚")
                        st.stop()
                    elif generation_errors:
                        st.warning("éƒ¨åˆ†éŸ³é¢‘ç”Ÿæˆå¤±è´¥ï¼Œå°†ä½¿ç”¨å·²ç”Ÿæˆçš„éŸ³é¢‘ç»§ç»­ã€‚")

                    if individual_audio_files:
                        final_podcast_path = os.path.join(temp_dir, "final_podcast.mp3")
                        concatenated_audio = concatenate_audio_files(individual_audio_files, final_podcast_path)
                        if concatenated_audio:
                            st.session_state.final_audio_path = concatenated_audio
                            st.success("æ’­å®¢ç”ŸæˆæˆåŠŸï¼")
                        else:
                            st.error("éŸ³é¢‘æ–‡ä»¶åˆå¹¶å¤±è´¥ã€‚")
                    else:
                        st.error("æœªæˆåŠŸç”Ÿæˆä»»ä½•éŸ³é¢‘ç‰‡æ®µï¼Œæ— æ³•åˆ›å»ºæ’­å®¢ã€‚")
    except json.JSONDecodeError:
        st.error("ç¼–è¾‘çš„å¯¹è¯ä¸æ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼ã€‚è¯·æ£€æŸ¥æ ¼å¼å¹¶é‡è¯•ã€‚")

# 4. Display final podcast
if st.session_state.final_audio_path:
    st.subheader("ğŸ§ æ”¶å¬æ’­å®¢")
    try:
        with open(st.session_state.final_audio_path, "rb") as ap:
            st.audio(ap.read(), format="audio/mp3")
        
        with open(st.session_state.final_audio_path, "rb") as fp:
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½æ’­å®¢ (MP3)",
                data=fp,
                file_name="generated_podcast.mp3",
                mime="audio/mpeg"
            )
    except FileNotFoundError:
        st.error("æœªæ‰¾åˆ°æœ€ç»ˆéŸ³é¢‘æ–‡ä»¶ã€‚ç”Ÿæˆæˆ–æ¸…ç†è¿‡ç¨‹ä¸­å¯èƒ½å‡ºç°é—®é¢˜ã€‚")
    except Exception as e:
        st.error(f"æ˜¾ç¤ºæˆ–ä¸‹è½½éŸ³é¢‘æ—¶å‡ºé”™ï¼š{e}")
